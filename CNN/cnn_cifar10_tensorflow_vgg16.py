# -*- coding: utf-8 -*-
"""CNN-Cifar10-Tensorflow-VGG16.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zCZ1Ht9Udx_jjPawsPiUuxIAva6uHl1k
"""

import tensorflow as tf
from tensorflow.keras import datasets,layers,models,regularizers,optimizers,callbacks
import matplotlib.pyplot as plt

(train_images,train_labels),(test_images,test_labels) = datasets.cifar10.load_data()

# image normalization
train_images,test_images = train_images/255.0,test_images/255.0

"""# check available gpu number"""

print("Num GPUs Available: ", len(tf.config.experimental.list_physical_devices('GPU')))

"""# verify data with visualization"""

class_names = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']

plt.figure(figsize=(10,10))
for i in range(25):
  plt.subplot(5,5,i+1)
  # set ticks 刻度
  plt.xticks([])
  plt.yticks([])
  plt.grid(False)
  plt.imshow(train_images[i],cmap=plt.cm.binary)

  plt.xlabel(class_names[train_labels[i][0]])
plt.show()

"""# VGG16 Model"""

from IPython.display import Image
Image(url="https://miro.medium.com/max/1050/1*HzxRI1qHXjiVXla-_NiMBA.jpeg")

"""# define VGG16"""

def VGG16(weight_decay=5e-4,dropout=0.5):
  model = models.Sequential()
  model.add(layers.Conv2D(64,(3,3),activation='relu',padding='same',input_shape=(32,32,3),kernel_regularizer=regularizers.l2(weight_decay)))
  model.add(layers.Conv2D(64,(3,3),activation='relu',padding='same',kernel_regularizer=regularizers.l2(weight_decay)))
  model.add(layers.MaxPooling2D((2,2)))

  model.add(layers.Conv2D(128,(3,3),activation='relu',padding='same',kernel_regularizer=regularizers.l2(weight_decay)))
  model.add(layers.Conv2D(128,(3,3),activation='relu',padding='same',kernel_regularizer=regularizers.l2(weight_decay)))
  model.add(layers.MaxPooling2D((2,2)))

  model.add(layers.Conv2D(256,(3,3),activation='relu',padding='same',kernel_regularizer=regularizers.l2(weight_decay)))
  model.add(layers.Conv2D(256,(3,3),activation='relu',padding='same',kernel_regularizer=regularizers.l2(weight_decay)))
  model.add(layers.Conv2D(256,(3,3),activation='relu',padding='same',kernel_regularizer=regularizers.l2(weight_decay)))
  model.add(layers.MaxPooling2D((2,2)))

  model.add(layers.Conv2D(512,(3,3),activation='relu',padding='same',kernel_regularizer=regularizers.l2(weight_decay)))
  model.add(layers.Conv2D(512,(3,3),activation='relu',padding='same',kernel_regularizer=regularizers.l2(weight_decay)))
  model.add(layers.Conv2D(512,(3,3),activation='relu',padding='same',kernel_regularizer=regularizers.l2(weight_decay)))
  model.add(layers.MaxPooling2D((2,2)))

  model.add(layers.Conv2D(512,(3,3),activation='relu',padding='same',kernel_regularizer=regularizers.l2(weight_decay)))
  model.add(layers.Conv2D(512,(3,3),activation='relu',padding='same',kernel_regularizer=regularizers.l2(weight_decay)))
  model.add(layers.Conv2D(512,(3,3),activation='relu',padding='same',kernel_regularizer=regularizers.l2(weight_decay)))
  model.add(layers.MaxPooling2D((2,2)))

  model.add(layers.Flatten())
  model.add(layers.Dense(4096,activation='relu'))
  model.add(layers.Dropout(dropout))
  model.add(layers.Dense(1000,activation='relu'))
  model.add(layers.Dropout(dropout))
  model.add(layers.Dense(10,activation='softmax'))

  return model

"""# check model"""

model = VGG16()
model.summary()

"""# train model"""

# optimizer and learning rate
learning_rate= 0.01
epoch_num=10
sgd = optimizers.SGD(lr=learning_rate,momentum=0.9,nesterov=True)
def VGGScheduler(epoch,learning_rate):
  if epoch<epoch_num*0.4:
    return learning_rate
  if epoch<epoch_num*0.8:
    return learning_rate*0.1
  return learning_rate*0.01
update_lr = callbacks.LearningRateScheduler(VGGScheduler)

# early stopping when val_acc goes high
earlyStopping = callbacks.EarlyStopping(
    monitor= "val_accuracy",
    # minimum improvement
    min_delta=0,
    # Number of epochs with no improvements  
    patience=40,
    verbose=1,
    mode='auto'

)
# model checkpoint
saveModel = callbacks.ModelCheckpoint("vgg16_1.hdf5",
                    monitor='val_loss',
                    save_best_only=True,
                    save_weights_only=False,
                    mode="auto",
                    save_freq="epoch")

# compile
model.compile(optimizer=sgd,loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])
model.fit(train_images,train_labels,
          batch_size=10,
          epochs=epoch_num,
          callbacks=[update_lr,saveModel,earlyStopping],
          validation_data=(test_images,test_labels))

"""# model evaluation"""

# accuracy: acc of train data (number of predictions matching labels/total count)
# val_accuracy: acc of test data
plt.plot(history.history['accuracy'],label='accuracy')
plt.plot(history.history['val_accuracy'],label='val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0.5,1])
plt.legend(loc='lower right')
plt.show()