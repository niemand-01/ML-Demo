# -*- coding: utf-8 -*-
"""RNN-Tensorflow-Text Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KpK-P6ZFTq0-0A2UpI23TFFU1-U9ZbeG
"""

import tensorflow_datasets as tfds
import tensorflow as tf
from tensorflow.keras.layers import *

import matplotlib.pyplot as plt

# dataset
dataset,info = tfds.load('imdb_reviews/subwords8k',with_info=True,as_supervised=True)
train_dataset,test_dataset = dataset['train'],dataset['test']

"""# Text Tokenizer with Encoder"""

encoder = info.features['text'].encoder
print('vocalbulary size:{}'.format(encoder.vocab_size))

sample_string = 'Hello TensorFlow.'
encoded_string = encoder.encode(sample_string)
print('Encoded string is{}'.format(encoded_string))

original_string = encoder.decode(encoded_string)
print('Original string is {}'.format(original_string))

assert original_string == sample_string
for index in encoded_string:
  print('{} -- &gt;{}'.format(index,encoder.decode([index])))

"""# Prepare Data"""

BUFFER_SIZE = 10000
BATCH_SIZE = 20

train_dataset = train_dataset.shuffle(BUFFER_SIZE)
train_dataset = train_dataset.padded_batch(BATCH_SIZE)

test_dataset = test_dataset.padded_batch(BATCH_SIZE)

# 建立迭代器，并进行迭代操作（把data从DatasetV1Adapter格式转化为tensor格式）
for element in train_dataset:
  print(element)
  break

# 每个element里面有2个array,
# 第一个shape(7,64,64,3944) 存放评论的话，已经encoded，
  # 其中3944是每句话的长度
  # 7，64，64是相对应的句子个数

# 第二个(7,64,64)，应该是相对应的Label（1 good/0 bad）

"""# Model"""

model = tf.keras.Sequential([
      Embedding(encoder.vocab_size,64),
      Bidirectional(LSTM(64)),
      Dense(64,activation='relu'),
      Dense(1)
])

LEARNING_RATE =1e-4

model.compile(
    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),
    optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),
    metrics=['accuracy']
)

histroy = model.fit(train_dataset,epochs=10,validation_data=test_dataset,validation_steps=30)

"""# Evaluation"""

test_loss,test_acc = model.evaluate(test_dataset)
print('Test Loss:{}'.format(test_loss))
print('Test Accuracy'.format(test_acc))

def plot_graphs(history,metric):
  plt.plot(history.history[metric])
  plt.plot(history.history["val_"+metric],'')
  plt.xlabel('Epochs')
  plt.ylabel(metric)
  plt.legend([metric,'val_'+metric])
  plt.show()

plot_graphs(histroy,'accuracy')

"""# Prediction"""

def pad_to_size(vec,size):
  zeros = [0]*(size-len(vec))
  vec.extend(zeros)
  return vec

def sample_predict(sample_pred_text,pad):
  encoded_sample = encoder.encode(sample_pred_text)

  if pad:
    encoded_sample = pad_to_size(encoded_sample,64)
  encoded_sample = tf.cast(encoded_sample,tf.float32)
  predictions = model.predict(tf.expand_dims(encoded_sample,0))
  return predictions

# predict on a smaple text without padding
sample_pred_text_bad = ('The movie was not good. I would not recommend')
predictions = sample_predict(sample_pred_text_bad,pad=False)
print(predictions)

predictions = sample_predict(sample_pred_text_bad,pad=True)
print(predictions)

sample_pred_text_good = ('The movie was pretty good. I would like to recommend')
predictions = sample_predict(sample_pred_text_good,pad=True)
print(predictions)