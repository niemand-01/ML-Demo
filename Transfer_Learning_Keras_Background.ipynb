{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer-Learning-Keras-Background.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP2Wc+dgkgAt4aCAspFahTi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/niemand-01/ML-Demo/blob/master/Transfer_Learning_Keras_Background.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-byTgmuU8ZX"
      },
      "source": [
        "from tensorflow import keras\n",
        "import numpy as np"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "he3JJwIlSiyA"
      },
      "source": [
        "# 背景知识\n",
        "## Transfer learning 定义：\n",
        "Transfer learning consists of taking features learned on one problem, and leveraging them on a new, similar problem. For instance, features from a model that has learned to identify racoons may be useful to kick-start a model meant to identify tanukis.\n",
        "\n",
        "也就是将一个模型适用于另一个模型，设别浣熊到识别狸猫\n",
        "\n",
        "## Reason for transfer learning:\n",
        "Transfer learning is usually done for tasks where your dataset has too little data to train a full-scale model from scratch.\n",
        "\n",
        "## Most common incarnation of transfer learning(workflow):\n",
        "1. Take layers from a previously trained model.\n",
        "2. Freeze them, so as to avoid destroying any of the information they contain during future training rounds.\n",
        "3. Add some new, trainable layers on top of the frozen layers. They will learn to turn the old features into predictions on a new dataset.\n",
        "4. Train the new layers on your dataset.\n",
        "5. __Finetuning__ which consists of unfreezing the entire model you obtained above (or part of it), and re-training it on the new data with a very low learning rate. This can potentially achieve meaningful improvements, by incrementally adapting the pretrained features to the new data.(optional step)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnUmTo3GUqWP"
      },
      "source": [
        "# 理解 trainable attribute\n",
        "## example: Dense layer has 2 trainable weights(kernel&bias)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBTXg7ktSYSG",
        "outputId": "52ba9dde-5d97-42c8-c365-803ac8596495",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "layer = keras.layers.Dense(3)\n",
        "layer.build((None,4))\n",
        "\n",
        "print(\"weights:\",len(layer.weights))\n",
        "print(\"trainable_weights:\", len(layer.trainable_weights))\n",
        "print(\"non_trainable_weights:\", len(layer.non_trainable_weights))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weights: 2\n",
            "trainable_weights: 2\n",
            "non_trainable_weights: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tN3vvM1VWe9X"
      },
      "source": [
        "## example: BatchNormalization layer has 2 trainable , 2non-trainable weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOxRkTOvWcRY",
        "outputId": "4aa841bc-3495-433a-d9ae-dd84cb59a7e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "layer = keras.layers.BatchNormalization()\n",
        "layer.build((None, 4))  # Create the weights\n",
        "\n",
        "print(\"weights:\", len(layer.weights))\n",
        "print(\"trainable_weights:\", len(layer.trainable_weights))\n",
        "print(\"non_trainable_weights:\", len(layer.non_trainable_weights))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weights: 4\n",
            "trainable_weights: 2\n",
            "non_trainable_weights: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9VP2q-GWxK7"
      },
      "source": [
        "## example: set trainable attribute to False:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfrUHmtWWz7b",
        "outputId": "b2743961-734e-4bf9-8dbd-107719a566df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "layer = keras.layers.Dense(3)\n",
        "layer.build((None, 4))  # Create the weights\n",
        "layer.trainable = False  # Freeze the layer\n",
        "\n",
        "print(\"weights:\", len(layer.weights))\n",
        "print(\"trainable_weights:\", len(layer.trainable_weights))\n",
        "print(\"non_trainable_weights:\", len(layer.non_trainable_weights))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weights: 2\n",
            "trainable_weights: 0\n",
            "non_trainable_weights: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5S9k85rcW7au"
      },
      "source": [
        "## example: when a trainable weight becomes non-trainable, its value is no longer updated during training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZuOj1ywXC52",
        "outputId": "649a9701-9be9-4b93-be66-d0251957c7f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "layer1 = keras.layers.Dense(3, activation=\"relu\")\n",
        "layer2 = keras.layers.Dense(3, activation=\"sigmoid\")\n",
        "model = keras.Sequential([keras.Input(shape=(3,)), layer1, layer2])\n",
        "\n",
        "# Freeze the first layer\n",
        "layer1.trainable = False\n",
        "\n",
        "# Keep a copy of the weights of layer1 for later reference\n",
        "initial_layer1_weights_values = layer1.get_weights()\n",
        "\n",
        "# Train the model\n",
        "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "model.fit(np.random.random((2, 3)), np.random.random((2, 3)))\n",
        "\n",
        "# Check that the weights of layer1 have not changed during training\n",
        "final_layer1_weights_values = layer1.get_weights()\n",
        "\n",
        "# assert consistency before-train and after-train values of layer1 weights\n",
        "np.testing.assert_allclose(\n",
        "    initial_layer1_weights_values[0], final_layer1_weights_values[0]\n",
        ")\n",
        "np.testing.assert_allclose(\n",
        "    initial_layer1_weights_values[1], final_layer1_weights_values[1]\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0936\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-77GaYlXg6pb"
      },
      "source": [
        "## example: recursive setting of the trainable attribute"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RktKoX1Cg_bf"
      },
      "source": [
        "inner_model = keras.Sequential([\n",
        "            keras.Input(shape=(3,))\n",
        "            keras.layers.Dense(3,activation=\"relu\"),\n",
        "            keras,layers.Dense(3,activation=\"relu\"),\n",
        "])\n",
        "\n",
        "model = keras.Sequential([\n",
        "              keras.Input(shape=(3,)),\n",
        "              inner_model,\n",
        "              keras.layers.Dense(3,activation=\"sigmoid\"),\n",
        "])\n",
        "\n",
        "model.trainable = False # freeze the outer model\n",
        "\n",
        "assert inner_model.trainable == False # All layers in `model` are now frozen\n",
        "assert inner_model.layers[0].trainable == False  # `trainable` is propagated recursively"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}